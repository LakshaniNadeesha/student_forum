{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36da7271-d249-4d8d-994c-ee25484827c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (1.26.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.0/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "     ---- ----------------------------------- 0.2/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 0.3/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 0.4/1.5 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 0.5/1.5 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.7/1.5 MB 2.2 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 0.8/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 1.0/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 1.2/1.5 MB 2.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 1.3/1.5 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 1.4/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.5/1.5 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2023.12.25-cp39-cp39-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 42.0/42.0 kB 675.2 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ----------------------------------- ---- 51.2/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading regex-2023.12.25-cp39-cp39-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 92.2/269.5 kB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 194.6/269.5 kB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.5/269.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 71.7/78.3 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.3/78.3 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.12.25 tqdm-4.66.1\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp39-cp39-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from gensim) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\user\\ml_web_app\\venv\\lib\\site-packages (from gensim) (1.11.4)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading gensim-4.3.2-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB 1.4 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 0.1/24.0 MB 880.9 kB/s eta 0:00:28\n",
      "   ---------------------------------------- 0.1/24.0 MB 722.1 kB/s eta 0:00:34\n",
      "   ---------------------------------------- 0.2/24.0 MB 821.4 kB/s eta 0:00:30\n",
      "   ---------------------------------------- 0.2/24.0 MB 919.0 kB/s eta 0:00:26\n",
      "   ---------------------------------------- 0.3/24.0 MB 787.7 kB/s eta 0:00:31\n",
      "    --------------------------------------- 0.3/24.0 MB 884.2 kB/s eta 0:00:27\n",
      "    --------------------------------------- 0.4/24.0 MB 919.0 kB/s eta 0:00:26\n",
      "    --------------------------------------- 0.4/24.0 MB 875.2 kB/s eta 0:00:27\n",
      "    --------------------------------------- 0.5/24.0 MB 921.6 kB/s eta 0:00:26\n",
      "    --------------------------------------- 0.5/24.0 MB 956.5 kB/s eta 0:00:25\n",
      "    --------------------------------------- 0.6/24.0 MB 967.0 kB/s eta 0:00:25\n",
      "   - -------------------------------------- 0.7/24.0 MB 999.0 kB/s eta 0:00:24\n",
      "   - -------------------------------------- 0.7/24.0 MB 946.8 kB/s eta 0:00:25\n",
      "   - -------------------------------------- 0.7/24.0 MB 946.8 kB/s eta 0:00:25\n",
      "   - -------------------------------------- 0.8/24.0 MB 983.4 kB/s eta 0:00:24\n",
      "   - -------------------------------------- 0.8/24.0 MB 923.2 kB/s eta 0:00:26\n",
      "   - -------------------------------------- 0.9/24.0 MB 966.5 kB/s eta 0:00:24\n",
      "   - -------------------------------------- 1.0/24.0 MB 988.5 kB/s eta 0:00:24\n",
      "   - -------------------------------------- 1.0/24.0 MB 1.0 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 1.1/24.0 MB 1.0 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 1.1/24.0 MB 1.0 MB/s eta 0:00:23\n",
      "   -- ------------------------------------- 1.2/24.0 MB 1.1 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 1.3/24.0 MB 1.1 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 1.4/24.0 MB 1.1 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 1.5/24.0 MB 1.1 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 1.6/24.0 MB 1.1 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 1.7/24.0 MB 1.2 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 1.8/24.0 MB 1.2 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.8/24.0 MB 1.2 MB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.9/24.0 MB 1.2 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 2.0/24.0 MB 1.3 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 2.1/24.0 MB 1.3 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 2.2/24.0 MB 1.3 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 2.3/24.0 MB 1.3 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 2.4/24.0 MB 1.4 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.6/24.0 MB 1.4 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.7/24.0 MB 1.4 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.7/24.0 MB 1.4 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.8/24.0 MB 1.4 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.9/24.0 MB 1.4 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 2.9/24.0 MB 1.4 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 3.0/24.0 MB 1.4 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 3.1/24.0 MB 1.4 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 3.2/24.0 MB 1.4 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.4/24.0 MB 1.4 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.4/24.0 MB 1.4 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.6/24.0 MB 1.5 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 3.7/24.0 MB 1.5 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 3.9/24.0 MB 1.5 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 3.9/24.0 MB 1.5 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 4.1/24.0 MB 1.5 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 4.1/24.0 MB 1.5 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 4.2/24.0 MB 1.5 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 4.3/24.0 MB 1.6 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 4.5/24.0 MB 1.6 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 4.6/24.0 MB 1.6 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 4.7/24.0 MB 1.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 4.9/24.0 MB 1.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 4.9/24.0 MB 1.6 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 5.1/24.0 MB 1.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 5.2/24.0 MB 1.7 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 5.4/24.0 MB 1.7 MB/s eta 0:00:12\n",
      "   --------- ------------------------------ 5.5/24.0 MB 1.7 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 5.5/24.0 MB 1.7 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 5.5/24.0 MB 1.7 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 5.7/24.0 MB 1.7 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 5.8/24.0 MB 1.7 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 5.9/24.0 MB 1.7 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 6.1/24.0 MB 1.7 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 6.2/24.0 MB 1.7 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 6.4/24.0 MB 1.7 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 6.6/24.0 MB 1.8 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 6.7/24.0 MB 1.8 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 6.8/24.0 MB 1.8 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 6.9/24.0 MB 1.8 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 7.1/24.0 MB 1.8 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 7.2/24.0 MB 1.8 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 7.4/24.0 MB 1.8 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 7.6/24.0 MB 1.9 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 7.7/24.0 MB 1.9 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 7.9/24.0 MB 1.9 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.1/24.0 MB 1.9 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 8.2/24.0 MB 1.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 8.4/24.0 MB 1.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 8.6/24.0 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 8.7/24.0 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 8.9/24.0 MB 2.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 8.9/24.0 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.0/24.0 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.1/24.0 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.3/24.0 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.4/24.0 MB 2.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 9.6/24.0 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 9.8/24.0 MB 2.0 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 10.0/24.0 MB 2.0 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 10.2/24.0 MB 2.0 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 10.4/24.0 MB 2.1 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 10.6/24.0 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 10.8/24.0 MB 2.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 11.0/24.0 MB 2.4 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 11.2/24.0 MB 2.4 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 11.4/24.0 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 11.7/24.0 MB 2.5 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 11.9/24.0 MB 2.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 12.2/24.0 MB 2.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 12.4/24.0 MB 2.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 12.7/24.0 MB 2.8 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 12.9/24.0 MB 2.8 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 13.2/24.0 MB 2.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.4/24.0 MB 2.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.5/24.0 MB 3.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.5/24.0 MB 3.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.6/24.0 MB 2.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 13.9/24.0 MB 3.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.1/24.0 MB 3.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.4/24.0 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 14.6/24.0 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 14.9/24.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.1/24.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.4/24.0 MB 3.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 15.7/24.0 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 15.9/24.0 MB 3.5 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.2/24.0 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.5/24.0 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.7/24.0 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.0/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.1/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.1/24.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.2/24.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.2/24.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.2/24.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.5/24.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.6/24.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.6/24.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.6/24.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.6/24.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.8/24.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.8/24.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.8/24.0 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.9/24.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.9/24.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.1/24.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.2/24.0 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.4/24.0 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.5/24.0 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.7/24.0 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.9/24.0 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.1/24.0 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.3/24.0 MB 3.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.5/24.0 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.7/24.0 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.0/24.0 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.2/24.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.2/24.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.2/24.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.2/24.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.2/24.0 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.2/24.0 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.3/24.0 MB 3.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.4/24.0 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.6/24.0 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.6/24.0 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.7/24.0 MB 3.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.7/24.0 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.8/24.0 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.8/24.0 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 20.9/24.0 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 21.0/24.0 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 21.2/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.3/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.7/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.8/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.0/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.2/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.4/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.6/24.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.7/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 22.8/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.0/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.2/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.3/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.5/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.6/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.8/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.0/57.0 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-6.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install scikit-learn\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b68d94d-1be6-4aa0-9618-bec17423d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('messages.csv',encoding='windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "522974bf-a87f-4c4d-8c1d-5123691ad8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent</th>\n",
       "      <th>student</th>\n",
       "      <th>created</th>\n",
       "      <th>subject</th>\n",
       "      <th>message</th>\n",
       "      <th>attachment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>student 1</td>\n",
       "      <td>12 January 2010, 10:49 PM</td>\n",
       "      <td>About ISDN</td>\n",
       "      <td>Can any one tell me about ISDN?</td>\n",
       "      <td>0</td>\n",
       "      <td>C-TE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>student 1</td>\n",
       "      <td>student 2</td>\n",
       "      <td>13 January 2010, 12:43 PM</td>\n",
       "      <td>About ISDN</td>\n",
       "      <td>(ISDN) = Integrted Services Digital Netork is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>C-IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>student 2</td>\n",
       "      <td>student 1</td>\n",
       "      <td>13 January 2010, 03:28 PM</td>\n",
       "      <td>About ISDN</td>\n",
       "      <td>Thank you friend.....</td>\n",
       "      <td>0</td>\n",
       "      <td>C-RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>student 1</td>\n",
       "      <td>student 3</td>\n",
       "      <td>14 January 2010, 06:18 PM</td>\n",
       "      <td>About ISDN</td>\n",
       "      <td>IDSN is basicly a digital dailup connection, y...</td>\n",
       "      <td>0</td>\n",
       "      <td>C-EX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>student 1</td>\n",
       "      <td>student 4</td>\n",
       "      <td>13 January 2010, 02:55 PM</td>\n",
       "      <td>About ISDN</td>\n",
       "      <td>Integrated Services Digital Network (ISDN) is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>C-EX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      parent    student                    created     subject  \\\n",
       "0       none  student 1  12 January 2010, 10:49 PM  About ISDN   \n",
       "1  student 1  student 2  13 January 2010, 12:43 PM  About ISDN   \n",
       "2  student 2  student 1  13 January 2010, 03:28 PM  About ISDN   \n",
       "3  student 1  student 3  14 January 2010, 06:18 PM  About ISDN   \n",
       "4  student 1  student 4  13 January 2010, 02:55 PM  About ISDN   \n",
       "\n",
       "                                             message  attachment label  \n",
       "0                    Can any one tell me about ISDN?           0  C-TE  \n",
       "1  (ISDN) = Integrted Services Digital Netork is ...           0  C-IN  \n",
       "2                              Thank you friend.....           0  C-RA  \n",
       "3  IDSN is basicly a digital dailup connection, y...           0  C-EX  \n",
       "4  Integrated Services Digital Network (ISDN) is ...           0  C-EX  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6910f612-e453-484b-ba6c-a0d1c1a11b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parent        0\n",
       "student       0\n",
       "created       0\n",
       "subject       0\n",
       "message       0\n",
       "attachment    0\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2bf893e-9d2f-4f89-94a3-aeb8526c4b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize and lowercase\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove punctuation and other non-alphabetic characters\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f02316f-0ec2-45d0-829b-936f51cfae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Named Entities\n",
    "from nltk import ne_chunk\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    tokens = preprocess_text(text)\n",
    "    tagged_tokens = nltk.pos_tag(tokens)\n",
    "    named_entities = ne_chunk(tagged_tokens)\n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb1b287-f0f0-4f9f-ad8a-ae5f98235bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Named Entities\n",
    "def count_named_entities(text):\n",
    "    named_entities = extract_named_entities(text)\n",
    "    count = sum(1 for chunk in named_entities if hasattr(chunk, 'label'))\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f43f75-98b6-4012-86a6-3bcd97b32758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cohesion\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def compute_cohesion(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Tokenize each sentence into words\n",
    "    tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "\n",
    "    # Flatten the list of lists\n",
    "    words = [word for sentence in tokenized_sentences for word in sentence if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    # Compute word overlap between consecutive sentences\n",
    "    word_overlap_count = 0\n",
    "    for i in range(len(tokenized_sentences) - 1):\n",
    "        sentence1 = set(tokenized_sentences[i])\n",
    "        sentence2 = set(tokenized_sentences[i + 1])\n",
    "        word_overlap_count += len(sentence1.intersection(sentence2))\n",
    "\n",
    "    # Compute cohesion as the total word overlap normalized by the total number of words\n",
    "    total_words = len(words)\n",
    "    cohesion = word_overlap_count / total_words if total_words > 0 else 0\n",
    "\n",
    "    return cohesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ffa256-084a-4a56-9c00-9fb55360e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated Coherence\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def calculate_coherence(text):\n",
    "    # Tokenize the text into sentences and words\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = [word.lower() for sentence in sentences for word in word_tokenize(sentence)]\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    # Calculate bigrams\n",
    "    bi_grams = list(bigrams(words))\n",
    "\n",
    "    # Calculate frequency distribution of words and bigrams\n",
    "    freq_dist_words = FreqDist(words)\n",
    "    freq_dist_bigrams = FreqDist(bi_grams)\n",
    "\n",
    "    # Calculate Pointwise Mutual Information (PMI)\n",
    "    coherence = sum([freq_dist_bigrams[bigram] * freq_dist_words[bigram[0]] * freq_dist_words[bigram[1]] for bigram in bi_grams])\n",
    "\n",
    "    return coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c0e099-76ef-414d-a6cf-c7da596a37aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate word count of a given text\n",
    "\n",
    "def word_count(text):\n",
    "    # Use split() to break the text into words\n",
    "    words = text.split()\n",
    "\n",
    "    # Count the number of words\n",
    "    count = len(words)\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca4de0a1-7bb1-4a4f-a185-e2120d92d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Feature to Your Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'messages' is your DataFrame with columns 'message' and 'label'\n",
    "data['named_entities_count'] = data['message'].apply(count_named_entities)\n",
    "data['cohesion'] = data['message'].apply(compute_cohesion)\n",
    "data['coherence'] = data['message'].apply(calculate_coherence)\n",
    "data['wc'] = data['message'].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f3ea60-a33d-4220-b84b-0400db326597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.38524590163934425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        C-EX       0.31      0.36      0.33        39\n",
      "        C-IN       0.48      0.57      0.52        51\n",
      "        C-RA       0.00      0.00      0.00        15\n",
      "        C-TE       0.27      0.24      0.25        17\n",
      "\n",
      "    accuracy                           0.39       122\n",
      "   macro avg       0.26      0.29      0.28       122\n",
      "weighted avg       0.34      0.39      0.36       122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Assuming your dataset is stored in a DataFrame named 'data'\n",
    "# Preprocess the 'created' column\n",
    "data['created'] = pd.to_datetime(data['created'])\n",
    "data['hour'] = data['created'].dt.hour  # Extract hour as a feature\n",
    "\n",
    "# Combine text features\n",
    "data['combined_text'] = data[['parent', 'student', 'subject', 'message']].astype(str).agg(' '.join, axis=1)\n",
    "\n",
    "# Tokenize the text\n",
    "data['tokenized_text'] = data['combined_text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=data['tokenized_text'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to average Word2Vec vectors for a text\n",
    "def average_word2vec(tokens, model, vector_size):\n",
    "    vector_sum = sum(model.wv[word] for word in tokens if word in model.wv)\n",
    "    return vector_sum / len(tokens) if len(tokens) > 0 else np.zeros(vector_size)\n",
    "\n",
    "# Create Word2Vec vectors for each text\n",
    "data['word2vec'] = data['tokenized_text'].apply(lambda x: average_word2vec(x, word2vec_model, vector_size=100))\n",
    "\n",
    "# Convert Word2Vec vectors to DataFrame columns\n",
    "word2vec_columns = pd.DataFrame(data['word2vec'].to_list(), columns=[f'w2v_{i}' for i in range(100)])\n",
    "\n",
    "# Combine Word2Vec features, hour, and other features\n",
    "X_combined = pd.concat([word2vec_columns, data[['hour', 'named_entities_count', 'cohesion', 'coherence', 'wc']]], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b82f87fa-d33c-4fdd-99df-2071301e73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file using pickle\n",
    "model_filename = \"rf_model.pickle\"\n",
    "\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump((rf_model,word2vec_model), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d0682-6d78-4e24-a7dd-8d215b5b1d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
